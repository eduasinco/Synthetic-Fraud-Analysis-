{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import roc_auc_score as auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/eduardorodriguez/Desktop/DATA/syndata/syndata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "X = X[:100000]\n",
    "y = X['isFraud']\n",
    "X = X.drop(['nameOrig', 'nameDest','isFlaggedFraud'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X,prefix=['type'])\n",
    "X = X.drop(['isFraud'], axis = 1)\n",
    "df = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data by 50-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.5\n",
    "df.sort_values('Time', inplace = True)\n",
    "TRA_INDEX = int((1-TEST_RATIO) * df.shape[0])\n",
    "train_x = df.iloc[:TRA_INDEX, 1:-2].values\n",
    "train_y = df.iloc[:TRA_INDEX, -1].values\n",
    "\n",
    "test_x = df.iloc[TRA_INDEX:, 1:-2].values\n",
    "test_y = df.iloc[TRA_INDEX:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing - z scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mean = []\n",
    "cols_std = []\n",
    "for c in range(train_x.shape[1]):\n",
    "    cols_mean.append(train_x[:,c].mean())\n",
    "    cols_std.append(train_x[:,c].std())\n",
    "    train_x[:, c] = (train_x[:, c] - cols_mean[-1]) / cols_std[-1]\n",
    "    test_x[:, c] =  (test_x[:, c] - cols_mean[-1]) / cols_std[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbm import RBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model object with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RBM(train_x.shape[1], 10, visible_unit_type='gauss', main_dir='/home/weimin/rbm/model', model_name='rbm_model.ckpt',\n",
    "                 gibbs_sampling_steps=4, learning_rate=0.001, momentum = 0.95, batch_size=512, num_epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train it and plot training reconstruction loss v.s. iteractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, validation_set=test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on val - Free Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cost = model.getFreeEnergy(test_x).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC-ROC curve on val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(test_y, test_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(test_y, test_cost)\n",
    "\n",
    "fpr_micro, tpr_micro, _ = roc_curve(test_y, test_cost)\n",
    "roc_auc = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve on val data set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution for FE on val set - fraud and non-fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(test_cost[np.where(test_y == 1)], bins = 100)\n",
    "plt.title('Free energy distribution of val set')\n",
    "plt.xlabel('Free energy')\n",
    "plt.ylabel('Probabilties')\n",
    "plt.hist(test_cost[(test_y == 0) & (test_cost < 500)], bins = 100, color='green', normed=1.0, label='Non-Fraud')\n",
    "plt.hist(test_cost[(test_y == 1) & (test_cost < 500)], bins = 100, color='red', normed=1.0, label = 'Fraud')\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(test_cost[np.where(test_y == 1)], bins = 100)\n",
    "plt.hist(test_cost[(test_y == 0) & (test_cost < 500)], bins = 100, color='green', normed=1)\n",
    "plt.title('Free energy distribution of non-fraud cases')\n",
    "plt.xlabel('Free energy')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(test_cost[np.where(test_y == 1)], bins = 100)\n",
    "plt.hist(test_cost[(test_y == 1) & (test_cost < 500)], bins = 100, color='red', normed=1)\n",
    "plt.title('Free energy distribution of fraud cases')\n",
    "plt.xlabel('Free energy')\n",
    "plt.ylabel('Probabilities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a threshold for real time fraud detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Curve in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_precision_recall(lines):\n",
    "    \n",
    "\n",
    "    for precision, recall, label in lines:\n",
    "        plt.plot(recall, precision, label=label)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    \n",
    "lines = []\n",
    "precision, recall, threshold = precision_recall_curve(test_y, test_cost)\n",
    "\n",
    "lines.append( (precision, recall, 'Precision Recall Curve') )\n",
    "plot_precision_recall(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a threshold of Free Energy on range(0, 200) that best balances Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "all_pos = sum(test_y)\n",
    "for threshold in range(1, 200):\n",
    "    all_predicted = sum(test_cost > threshold)\n",
    "    TP = sum((test_cost > threshold) & (test_y == 1))\n",
    "    \n",
    "    precisions.append(TP  / all_predicted)\n",
    "    recalls.append(TP / all_pos)\n",
    "\n",
    "plt.plot( recalls, label = 'recall')\n",
    "plt.axvline(100, color = 'red')\n",
    "\n",
    "plt.title(\"Recall curve\")\n",
    "plt.xlabel(\"FE\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( precisions, label = 'precision')\n",
    "plt.axvline(100, color = 'red')\n",
    "\n",
    "plt.title(\"Precision curve\")\n",
    "plt.xlabel(\"FE\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Take a look at the top 500 transactions for example ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_500 = sorted(test_cost)[-500]\n",
    "population_mean = np.mean(test_y)\n",
    "model_mean_500 = np.mean(test_y[test_cost > value_500])\n",
    "print(\"Perc of fraud in val data is: %0.2f%%; perc of fraud in top 500 by model is: %0.2f%%\" % (population_mean*100, model_mean_500*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
